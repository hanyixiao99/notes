# 19 卷积层

## 分类猫和狗的图片

从一个简单的例子出发

使用一个相机采集图片（12M像素），如果是RGB图片则有36M个元素，使用100大小的单隐藏层MLP，模型有3.6B个元素

## 两个原则

平移不变性

局部性

## 重新考察全连接层

如何从全连接层出发应用两个原则得到卷积

将输入和输出变形为矩阵

将权重变形为4-D张量 (h,w) 到 (h', w')

 <img src="/Users/hanyixiao/Library/Application Support/typora-user-images/截屏2021-12-09 19.13.47.png" alt="截屏2021-12-09 19.13.47" style="zoom:50%;" />

V 是 W 的重新索引

<img src="/Users/hanyixiao/Library/Application Support/typora-user-images/截屏2021-12-09 19.14.08.png" alt="截屏2021-12-09 19.14.08" style="zoom:50%;" />

### 原则1 平移不变性

输入x的平移导致h的平移，从 (i,j) 移动到 (i+a,j+b)

<img src="/Users/hanyixiao/Library/Application Support/typora-user-images/截屏2021-12-09 19.16.45.png" alt="截屏2021-12-09 19.16.45" style="zoom:50%;" />

v不应该依赖于  (i,j)

解决方案：<img src="/Users/hanyixiao/Library/Application Support/typora-user-images/截屏2021-12-09 19.18.45.png" alt="截屏2021-12-09 19.18.45" style="zoom:50%;" />

<img src="/Users/hanyixiao/Library/Application Support/typora-user-images/截屏2021-12-09 19.18.56.png" alt="截屏2021-12-09 19.18.56" style="zoom:50%;" />

这就是2维卷积，数学上严格应该叫做2维交叉相关

### 原则2 局部性

<img src="/Users/hanyixiao/Library/Application Support/typora-user-images/image-20211209192117580.png" alt="image-20211209192117580" style="zoom:50%;" />

当评估h时，我们不应该用远离 x~i,j~ 的参数

解决方案：当|a|,|b|>$\Delta$时，使得v~a,b~ =0

<img src="/Users/hanyixiao/Library/Application Support/typora-user-images/截屏2021-12-09 19.23.46.png" alt="截屏2021-12-09 19.23.46" style="zoom:50%;" />

所以说为什么卷积是特殊的全连接层

## 卷积层

### 二维交叉相关

<img src="/Users/hanyixiao/Library/Application Support/typora-user-images/截屏2021-12-09 19.26.52.png" alt="截屏2021-12-09 19.26.52" style="zoom:50%;" />

Kernel：卷积核，也就是上述局部性原则中delta = 1

### 二维卷积层

<img src="/Users/hanyixiao/Library/Application Support/typora-user-images/截屏2021-12-09 19.37.02.png" alt="截屏2021-12-09 19.37.02" style="zoom:50%;" />

## 例子

<img src="/Users/hanyixiao/Library/Application Support/typora-user-images/截屏2021-12-09 19.39.02.png" alt="截屏2021-12-09 19.39.02" style="zoom: 33%;" />

<img src="/Users/hanyixiao/Library/Application Support/typora-user-images/截屏2021-12-09 19.39.16.png" alt="截屏2021-12-09 19.39.16" style="zoom: 33%;" />

## 交叉相关 vs. 卷积

二维交叉相关

<img src="/Users/hanyixiao/Library/Application Support/typora-user-images/截屏2021-12-09 19.41.10.png" alt="截屏2021-12-09 19.41.10" style="zoom:50%;" />

二维卷积

<img src="/Users/hanyixiao/Library/Application Support/typora-user-images/截屏2021-12-09 19.41.20.png" alt="截屏2021-12-09 19.41.20" style="zoom:50%;" />

由于对称性，在实际使用中没有区别

## 一维和三维交叉相关

一维

<img src="/Users/hanyixiao/Library/Application Support/typora-user-images/截屏2021-12-09 19.45.15.png" alt="截屏2021-12-09 19.45.15" style="zoom:50%;" />

文本、语言、时间序列

三维

<img src="/Users/hanyixiao/Library/Application Support/typora-user-images/截屏2021-12-09 19.45.55.png" alt="截屏2021-12-09 19.45.55" style="zoom:50%;" />

视频、医学图像、气候地图

## 代码实现图像卷积

互相关运算

```python
import torch
from torch import nn
from d2l import torch as d2l

def corr2d(X, K):
    h, w = K.shape
    Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))
    for i in range(Y.shape[0]):
        for j in range(Y.shape[1]):
            Y[i, j] = (X[i:i + h, j:j + w] * K).sum()
    return Y
```

验证上述二维互相关运算的输出

```python
X = torch.tensor([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]])
K = torch.tensor([[0.0, 1.0], [2.0, 3.0]])
corr2d(X, K)
# tensor([[19., 25.],
#         [37., 43.]])
```

实现二维卷基层

```python
class Conv2D(nn.Module):
    def __init__(self, kernel_size):
        super().__init__()
        self.weight = nn.Parameter(torch.rand(kernel_size))
        self.bias = nn.Parameter(torch.zeros(1))

    def forward(self, x):
        return corr2d(x, self.weight) + self.bias
```

卷基层的一个简单应用：检测图像中不同颜色的边缘

```python
X = torch.ones((6, 8))
X[:, 2:6] = 0
X
# tensor([[1., 1., 0., 0., 0., 0., 1., 1.],
#         [1., 1., 0., 0., 0., 0., 1., 1.],
#         [1., 1., 0., 0., 0., 0., 1., 1.],
#         [1., 1., 0., 0., 0., 0., 1., 1.],
#         [1., 1., 0., 0., 0., 0., 1., 1.],
#         [1., 1., 0., 0., 0., 0., 1., 1.]])
```

检测`X`中颜色变化（1变为0）的边缘，构建一个核

```python
K = torch.tensor([[1.0, -1.0]])
```

如果元素没有变化的话，输出即为0，如果元素有变化，输出为1或-1

输出Y中的1代表从白色到黑色的边缘，-1代表从黑色到白色的边缘

```python
Y = corr2d(X, K)
Y
# tensor([[ 0.,  1.,  0.,  0.,  0., -1.,  0.],
#         [ 0.,  1.,  0.,  0.,  0., -1.,  0.],
#         [ 0.,  1.,  0.,  0.,  0., -1.,  0.],
#         [ 0.,  1.,  0.,  0.,  0., -1.,  0.],
#         [ 0.,  1.,  0.,  0.,  0., -1.,  0.],
#         [ 0.,  1.,  0.,  0.,  0., -1.,  0.]])
```

此时卷积核`K`只能检测垂直边缘

给定`X`和`Y`，学习由`X`生成`Y`的卷积核

```python
# 构造一个二维卷积层，它具有1个输出通道和形状为（1，2）的卷积核
conv2d = nn.Conv2d(1,1, kernel_size=(1, 2), bias=False)

# 这个二维卷积层使用四维输入和输出格式（批量大小、通道、高度、宽度），
# 其中批量大小和通道数都为1
X = X.reshape((1, 1, 6, 8))
Y = Y.reshape((1, 1, 6, 7))
lr = 3e-2  # 学习率

for i in range(10):
    Y_hat = conv2d(X)
    l = (Y_hat - Y) ** 2
    conv2d.zero_grad()
    l.sum().backward()
    # 迭代卷积核
    conv2d.weight.data[:] -= lr * conv2d.weight.grad
    if (i + 1) % 2 == 0:
        print(f'epoch {i+1}, loss {l.sum():.3f}')

# epoch 2, loss 23.248
# epoch 4, loss 8.319
# epoch 6, loss 3.205
# epoch 8, loss 1.279
# epoch 10, loss 0.518
```

所学的卷积核的权重张量

```python
conv2d.weight.data.reshape((1, 2)
# tensor([[ 0.9143, -1.0625]])
```

