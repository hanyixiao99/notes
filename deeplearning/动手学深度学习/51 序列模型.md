# 51 序列模型

<!--时序模型中，当前数据跟之前观察到的数据相关-->

<!--自回归模型使用自身过去的数据来预测未来-->

<!--马尔可夫模型假设当前只跟最近少数数据相关，从而简化模型-->

<!--潜变量模型使用潜变量来概括历史信息-->

考虑时间信息的模型

## 序列数据

实际中很多数据是有时序结构的（电影的评价随时间变化而变化）

- 音乐、语言、文本和视频都是连续的
- 大地震后的余震
- 人的互动是连续的
- 预测明天的股价

## 统计工具

在时间t观察到x~t~，那么得到T个不独立的随机变量(x~1~,...,x~T~)~p(x)

### 使用条件概率展开

<img src="/Users/hanyixiao/Library/Application Support/typora-user-images/截屏2021-12-16 12.55.40.png" alt="截屏2021-12-16 12.55.40" style="zoom:50%;" />

<img src="/Users/hanyixiao/Library/Application Support/typora-user-images/截屏2021-12-16 12.58.16.png" alt="截屏2021-12-16 12.58.16" style="zoom:50%;" />

也可以反向，在某些时刻有意义，但物理上不一定可行

<img src="/Users/hanyixiao/Library/Application Support/typora-user-images/截屏2021-12-16 12.59.32.png" alt="截屏2021-12-16 12.59.32" style="zoom:50%;" />

### 对条件概率建模

<img src="/Users/hanyixiao/Library/Application Support/typora-user-images/截屏2021-12-16 13.03.14.png" alt="截屏2021-12-16 13.03.14" style="zoom:50%;" />

计算p(x~t~)，给定了它之前t-1个数据

可以对前面t-1个数据进行建模表示为f函数（一个模型），来预测下一个模型

<img src="/Users/hanyixiao/Library/Application Support/typora-user-images/截屏2021-12-16 13.00.44.png" alt="截屏2021-12-16 13.00.44" style="zoom:50%;" />



对见过的数据建模，也称自回归模型

#### 方案A - 马尔可夫假设

假设当前数据只跟 $\tau$ 个过去数据点相关，每次预测新数据只需要看过去tau个

<img src="/Users/hanyixiao/Library/Application Support/typora-user-images/截屏2021-12-16 13.09.01.png" alt="截屏2021-12-16 13.09.01" style="zoom:50%;" />

<img src="/Users/hanyixiao/Library/Application Support/typora-user-images/截屏2021-12-16 13.09.43.png" alt="截屏2021-12-16 13.09.43" style="zoom:50%;" />

例如在过去数据上训练一个MLP模型

#### 方案B - 潜变量模型

引入潜变量h~t~来表示过去的信息 $h_t=f(x_1,...,x_{t-1})$

这样  $x_t=p(x_t|h_t)$

<img src="/Users/hanyixiao/Library/Application Support/typora-user-images/截屏2021-12-16 13.13.09.png" alt="截屏2021-12-16 13.13.09" style="zoom:50%;" />

## 代码实现

使用正弦函数和一些可加性噪声来生成序列数据，时间步为1，2，...，1000

```python
%matplotlib inline
import torch
from torch import nn
from d2l import torch as d2l

T = 1000  # 总共产生1000个点
time = torch.arange(1, T + 1, dtype=torch.float32)
x = torch.sin(0.01 * time) + torch.normal(0, 0.2, (T,))
d2l.plot(time, [x], 'time', 'x', xlim=[1, 1000], figsize=(6, 3))
```

<img src="/Users/hanyixiao/Library/Application Support/typora-user-images/截屏2021-12-16 13.17.22.png" alt="截屏2021-12-16 13.17.22" style="zoom:50%;" />

运用马尔可夫假设，将数据映射为数据对 $y_t=x_t$ 和 $\pmb{x}_t=[x_{t-\tau},...,x_{t-1}]$

```python
tau = 4
features = torch.zeros((T - tau, tau))
for i in range(tau):
    features[:, i] = x[i: T - tau + i]
labels = x[tau:].reshape((-1, 1))

batch_size, n_train = 16, 600
# 只有前n_train个样本用于训练
train_iter = d2l.load_array((features[:n_train], labels[:n_train]),
                            batch_size, is_train=True)
```

使用一个相当简单的结构：只是一个拥有两个全连接层的多层感知机

```python
# 初始化网络权重的函数
def init_weights(m):
    if type(m) == nn.Linear:
        nn.init.xavier_uniform_(m.weight)

# 一个简单的多层感知机
def get_net():
    net = nn.Sequential(nn.Linear(4, 10),
                        nn.ReLU(),
                        nn.Linear(10, 1))
    net.apply(init_weights)
    return net

# 平方损失。注意：MSELoss计算平方误差时不带系数1/2
loss = nn.MSELoss(reduction='none')
```

训练模型

```python
def train(net, train_iter, loss, epochs, lr):
    trainer = torch.optim.Adam(net.parameters(), lr)
    for epoch in range(epochs):
        for X, y in train_iter:
            trainer.zero_grad()
            l = loss(net(X), y)
            l.sum().backward()
            trainer.step()
        print(f'epoch {epoch + 1}, '
              f'loss: {d2l.evaluate_loss(net, train_iter, loss):f}')

net = get_net()
train(net, train_iter, loss, 5, 0.01)
# epoch 1, loss: 0.064482
# epoch 2, loss: 0.057770
# epoch 3, loss: 0.068805
# epoch 4, loss: 0.056088
# epoch 5, loss: 0.057325
```

模型预测下一个时间步

```python
onestep_preds = net(features)
d2l.plot([time, time[tau:]],
         [x.detach().numpy(), onestep_preds.detach().numpy()], 'time',
         'x', legend=['data', '1-step preds'], xlim=[1, 1000],
         figsize=(6, 3))
```

<img src="/Users/hanyixiao/Library/Application Support/typora-user-images/截屏2021-12-16 13.23.25.png" alt="截屏2021-12-16 13.23.25" style="zoom:50%;" />

进行多步预测（600开始）

误差不断累计使得偏移

```python
multistep_preds = torch.zeros(T)
multistep_preds[: n_train + tau] = x[: n_train + tau]
for i in range(n_train + tau, T):
    multistep_preds[i] = net(
        multistep_preds[i - tau:i].reshape((1, -1)))

d2l.plot([time, time[tau:], time[n_train + tau:]],
         [x.detach().numpy(), onestep_preds.detach().numpy(),
          multistep_preds[n_train + tau:].detach().numpy()], 'time',
         'x', legend=['data', '1-step preds', 'multistep preds'],
         xlim=[1, 1000], figsize=(6, 3))
```

<img src="/Users/hanyixiao/Library/Application Support/typora-user-images/截屏2021-12-16 13.25.44.png" alt="截屏2021-12-16 13.25.44" style="zoom:50%;" />

更多的多步预测

```python
max_steps = 64

features = torch.zeros((T - tau - max_steps + 1, tau + max_steps))
# 列i（i<tau）是来自x的观测，其时间步从（i+1）到（i+T-tau-max_steps+1）
for i in range(tau):
    features[:, i] = x[i: i + T - tau - max_steps + 1]

# 列i（i>=tau）是来自（i-tau+1）步的预测，其时间步从（i+1）到（i+T-tau-max_steps+1）
for i in range(tau, tau + max_steps):
    features[:, i] = net(features[:, i - tau:i]).reshape(-1)

steps = (1, 4, 16, 64)
d2l.plot([time[tau + i - 1: T - max_steps + i] for i in steps],
         [features[:, (tau + i - 1)].detach().numpy() for i in steps], 'time', 'x',
         legend=[f'{i}-step preds' for i in steps], xlim=[5, 1000],
         figsize=(6, 3))
```

<img src="/Users/hanyixiao/Library/Application Support/typora-user-images/截屏2021-12-16 13.27.49.png" alt="截屏2021-12-16 13.27.49" style="zoom:50%;" />