# 5.1 Bias & Variance

In statistic learning, we measure a model in terms for bias and variance

<img src="/Users/hanyixiao/Library/Application Support/typora-user-images/截屏2021-12-03 18.40.06.png" alt="截屏2021-12-03 18.40.06" style="zoom:50%;" />

## Bias-Variance Decomposition

Sample data $D=\{(x_1,y_1),...,(x_n,y_n)\}$ from $y=f(x)+\epsilon$

Learn $\hat{f}$  from $D$  by minimizing MSE, we want it generates well over different choices of $D$

<img src="/Users/hanyixiao/Library/Application Support/typora-user-images/截屏2021-12-03 18.52.17.png" alt="截屏2021-12-03 18.52.17" style="zoom:50%;" />

<img src="/Users/hanyixiao/Library/Application Support/typora-user-images/截屏2021-12-03 18.55.47.png" alt="截屏2021-12-03 18.55.47" style="zoom:50%;" />

## Bias-Variance Tradeoff

<img src="/Users/hanyixiao/Library/Application Support/typora-user-images/截屏2021-12-03 19.03.44.png" alt="截屏2021-12-03 19.03.44" style="zoom:50%;" />

## Reduce Bias & Variance

### Reduce Bias

A more complex model

- E.g. increase number of layers, number of hidden units in neural network

==Boosting==

==Stacking==

### Reduce Variance

A simpler model

Regularization, E.g. $L_2$ , $L_1$ , regularizations

==Bagging==

==Stacking==

### Reduce $\sigma^2$

Improve data

### Ensemble Learning

Use multiple models to improve predictive performance