# 3.6 Convolution Neural Networks 

## Dense layer to Convolution layer

Learn ImageNet (300*300 images with 1k classess) by a MLP with a single hidden layer with 10k outputs

- It leads to 1 billion (300x300x10k) learnable parameters, that's too big
- Fully connected: an output is a weighted sum over all inputs

Recognize objects in images

- ***Translation invariance***: similar output no matter where the object is
- ***Locality***: pixels are more related to near neighbors

Build the prior knowledge into the model structure

- Achieve same model capacity with less params

## Convolution Layer

***Locality***: an output is computed from k*k input windows

***Translation invariance***: outputs use the same k*k weights (kernel)

Model params of a conv layer does not depend on input/output sizes

A kernel way learn to identity a pattern

## Code (with PyTorch)

Convolution with single input and output channels

```python
# both input X and weight K are matrices
h, w = K.shape
Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))
for i in range(Y.shape[0]):
  for j in range(Y.shape[1]):
    Y[i, j] = (X[i : i + h, j : j + w] * K).sum()
```

## Pooling Layer

Convolution is sensitive to location

- A pixel shift in the input results in a pixel shift in output

A pooling layer computes mean/max in k*k windows

```python
# h, w: pooling window height and weight
# mode: max or avg
Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))
for i in range(Y.shape[0]):
  for j in range(Y.shape[1]):
    if mode == 'max':
      Y[i, j] = X[i : i + h, j : j + w].max()
    elif mode == 'avg':
      Y[i, j] = X[i : i + h, j : j + w].mean()
```

## Convolution Neural Networks (CNN)

A neural network uses stack of convolution layers to extract features

- Activation is applied after each convolution layer
- Using pooling to reduce location sensitivity

Model CNNs are deep neural network with various hyper-parameters and layer connections (AlexNet, VGG, Inceptions, ResNet, MobileNet)